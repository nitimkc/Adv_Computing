noObs <- length(y)
n <- length(result$datamatrix)
alpha <- result$alpha
#  to store prediction labels and error
ada.PredLabels <- matrix(NA, nrow = nrow(test), ncol = n)
ada.testerror <- rep(NA, n)
#  recursion
for(i in 1:n) {
#  predict labels and store
ada.predLabels[ ,i] <- predict(results$datamatrix[[i]], test, type="class")
ada.predLabels[ ,i] <- ifelse(ada.predLabels[ ,i]==2, 1, -1)
#  output the sign of a combination of all classifier outputs
ada.finalPred <- sign(rowSums(t(alpha[1:i] * t(ada.predLabels[ ,1:i]))))
#  final prediction error
ada.testerror[i] <- 1 - sum(ada.finalPred == y)/noObs #}
}
return(list(error=ada.testerror))
}
adaBoost.test(result = result, testData = data_test, testLabels = data_test[ ,1])
adaBoost.test <- function(result, testData, testLabels) {
#  ensure {1,-1} classes for labels
y <- ifelse( testLabels==1, 1, -1) # map to {1, -1}
#  initialization
noObs <- length(y)
n <- length(result$datamatrix)
alpha <- result$alpha
#  to store prediction labels and error
ada.PredLabels <- matrix(NA, nrow = nrow(testData), ncol = n)
ada.testerror <- rep(NA, n)
#  recursion
for(i in 1:n) {
#  predict labels and store
ada.predLabels[ ,i] <- predict(results$datamatrix[[i]], test, type="class")
ada.predLabels[ ,i] <- ifelse(ada.predLabels[ ,i]==2, 1, -1)
#  output the sign of a combination of all classifier outputs
ada.finalPred <- sign(rowSums(t(alpha[1:i] * t(ada.predLabels[ ,1:i]))))
#  final prediction error
ada.testerror[i] <- 1 - sum(ada.finalPred == y)/noObs #}
}
return(list(error=ada.testerror))
}
adaBoost.test(result = result, testData = data_test, testLabels = data_test[ ,1])
adaBoost.test <- function(result, testData, testLabels) {
#  ensure {1,-1} classes for labels
y <- ifelse( testLabels==1, 1, -1) # map to {1, -1}
#  initialization
noObs <- length(y)
n <- length(result$datamatrix)
alpha <- result$alpha
#  to store prediction labels and error
ada.PredLabels <- matrix(NA, nrow = nrow(testData), ncol = n)
ada.testerror <- rep(NA, n)
#  recursion
for(i in 1:n) {
#  predict labels and store
ada.predLabels[ ,i] <- predict(result$datamatrix[[i]], test, type="class")
ada.predLabels[ ,i] <- ifelse(ada.predLabels[ ,i]==2, 1, -1)
#  output the sign of a combination of all classifier outputs
ada.finalPred <- sign(rowSums(t(alpha[1:i] * t(ada.predLabels[ ,1:i]))))
#  final prediction error
ada.testerror[i] <- 1 - sum(ada.finalPred == y)/noObs #}
}
return(list(error=ada.testerror))
}
adaBoost.test(result = result, testData = data_test, testLabels = data_test[ ,1])
adaBoost.test <- function(result, testData, testLabels) {
#  ensure {1,-1} classes for labels
y <- ifelse( testLabels==1, 1, -1) # map to {1, -1}
#  initialization
noObs <- length(y)
n <- length(result$datamatrix)
alpha <- result$alpha
#  to store prediction labels and error
ada.PredLabels <- matrix(NA, nrow = nrow(testData), ncol = n)
ada.testerror <- rep(NA, n)
#  recursion
for(i in 1:n) {
#  predict labels and store
ada.predLabels[ ,i] <- predict(result$datamatrix[[i]], testData, type="class")
ada.predLabels[ ,i] <- ifelse(ada.predLabels[ ,i]==2, 1, -1)
#  output the sign of a combination of all classifier outputs
ada.finalPred <- sign(rowSums(t(alpha[1:i] * t(ada.predLabels[ ,1:i]))))
#  final prediction error
ada.testerror[i] <- 1 - sum(ada.finalPred == y)/noObs #}
}
return(list(error=ada.testerror))
}
adaBoost.test(result = result, testData = data_test, testLabels = data_test[ ,1])
adaBoost.test <- function(result, testData, testLabels) {
#  ensure {1,-1} classes for labels
y <- ifelse( testLabels==1, 1, -1) # map to {1, -1}
#  initialization
noObs <- length(y)
n <- length(result$datamatrix)
alpha <- result$alpha
#  to store prediction labels and error
ada.predLabels <- matrix(NA, nrow = nrow(testData), ncol = n)
ada.testerror <- rep(NA, n)
#  recursion
for(i in 1:n) {
#  predict labels and store
ada.predLabels[ ,i] <- predict(result$datamatrix[[i]], testData, type="class")
ada.predLabels[ ,i] <- ifelse(ada.predLabels[ ,i]==2, 1, -1)
#  output the sign of a combination of all classifier outputs
ada.finalPred <- sign(rowSums(t(alpha[1:i] * t(ada.predLabels[ ,1:i]))))
#  final prediction error
ada.testerror[i] <- 1 - sum(ada.finalPred == y)/noObs #}
}
return(list(error=ada.testerror))
}
adaBoost.test(result = result, testData = data_test, testLabels = data_test[ ,1])
ada.error <- adaBoost.test(result = result, testData = data_test, testLabels = data_test[ ,1])
if (!require("gbm")) install.packages("gbm"); library(gbm)
if (!require("ada")) install.packages("ada"); library(ada)
if (!require("gbm")) install.packages("gbm"); library(gbm)
gbmerror <- gbm(formula = formula, distribution = "adaboost",
data = data_test,
n.trees = noTrees,
interaction.depth = depth, shrinkage = 1, bag.fraction = 1)
gbmerror$train.error
ada.error
plot(ada.error, test = TRUE)
plot(ada.error)
## GBM to compare results
gbm <- gbm(formula = formula, distribution = "adaboost",
data = data_test,
n.trees = noTrees,
interaction.depth = depth, shrinkage = 1, bag.fraction = 1)
df <- cbind(ada.error, gbm$train.error)
plot(df)
View(df)
df <- cbind(ada.error$error, gbm$train.error)
View(df)
plot(ada.error$error, type = "l", col = "red",
main = "Compare own adaBoost function with gbm from R pkg",
xlab = "iter", ylab = "errors")
lines(gbm$train.error, type = "l", col="blue")
setwd("~/DATASCIENCE/2_Trimester/15D012ACM/problemSets/PS6")
data <- read.csv("~/DATASCIENCE/2_Trimester/15D012ACM/problemSets/PS5/spambase.data", header=FALSE)
formula <- V58~.
depth = 10
noTrees = 50
##  load reqd libraries
if (!require("caret")) install.packages("caret"); library(caret)
if (!require("gbm")) install.packages("gbm"); library(gbm)
if (!require("ggplot")) install.packages("ggplot"); library(ggplot)
source("adaBoost.R")
result <- adaBoost(formula = formula, data = data_train, depth = 10, noTrees = 20)
define rows to partition
part <- createDataPartition(data$V58, p=0.80, list=FALSE)
#  generate train and test sets
data_train <- data[part, ]
data_test <- data[-part, ]
##  train with the training set
source("adaBoost.R")
result <- adaBoost(formula = formula, data = data_train, depth = 10, noTrees = 20)
adaBoost.test <- function(result, testData, testLabels) {
#  set classes to {1,-1}
y <- ifelse( testLabels==1, 1, -1)
#  initialize
noObs <- length(y)
n <- length(result$datamatrix)
alpha <- result$alpha
#  to store prediction labels and error
ada.predLabels <- matrix(NA, nrow = nrow(testData), ncol = n)
ada.testerror <- rep(NA, n)
for(i in 1:n) {
#  predict labels and store
ada.predLabels[ ,i] <- predict(result$datamatrix[[i]], testData, type="class")
ada.predLabels[ ,i] <- ifelse(ada.predLabels[ ,i]==2, 1, -1)
#  output the sign of a combination of all classifier outputs
ada.finalPred <- sign(rowSums(t(alpha[1:i] * t(ada.predLabels[ ,1:i]))))
#  final prediction error
ada.testerror[i] <- 1 - sum(ada.finalPred == y)/noObs #}
}
return(list(error=ada.testerror))
}
ada.trainerror <- result$error
ada.testerror <- adaBoost.test(result = result, testData = data_test, testLabels = data_test[ ,1])
ada.test <- adaBoost.test(result = result, testData = data_test, testLabels = data_test[ ,1])
ada.testerror <- ada.test$error
View(data_test)
View(data_train)
gbm.data_test <- data_test
gbm.data_train <- data_train
View(gbm.data_test)
gbm.data_train <- data_train
gbm.data_test <- data_test
gbm.data_train$v58 <- ifelse( gbm.data_train$v58==1, 1, 0)
gbm.data_test$v58 <- ifelse( gbm.data_test$v58==1, 1, 0)
View(gbm.data_test)
gbm.data_train$V58 <- ifelse( gbm.data_train$V58==1, 1, 0)
gbm.data_test$V58 <- ifelse( gbm.data_test$V58==1, 1, 0)
gbm <- gbm(formula = formula,
distribution = "adaboost",
data = gbm.data_test,
n.trees = noTrees,
interaction.depth = depth,
shrinkage = 1, bag.fraction = 1)
# initialize error vectors
gbm.trainerror <- rep(NA, noTrees)
gbm.testerror <- rep(NA, noTrees)
gbm.trainerror[i] <- mean((predict(gbm, data_train, n.trees = i) > 0) != df.train2$y)
# save
gbm.trainerror[i] <- mean((predict(gbm, data_train, n.trees = 50) > 0) != df.train2$y)
gbm.testerror[i] <- mean((predict(gbm, data_test, n.trees = 50) > 0) != df.test2$y)
# save
gbm.trainerror[i] <- mean((predict(gbm, data_train, n.trees = 50) > 0) != gbm.data_train$V58)
gbm.testerror[i] <- mean((predict(gbm, data_test, n.trees = 50) > 0) != gbm.data_test$V58)
gbm.trainerror <- rep(NA, noTrees)
gbm.testerror <- rep(NA, noTrees)
gbm.trainerror[i] <- mean((predict(gbm, data_train, n.trees = 50) > 0) != gbm.data_train$V58)
gbm.testerror[i] <- mean((predict(gbm, data_test, n.trees = 50) > 0) != gbm.data_test$V58)
for (i in 1:noTrees) {
gbm.trainerror[i] <- mean((predict(gbm, data_train, n.trees = 50) > 0) != gbm.data_train$V58)
gbm.testerror[i] <- mean((predict(gbm, data_test, n.trees = 50) > 0) != gbm.data_test$V58)
}
gbm.trainerror
gbm.testerror
for (i in 1:noTrees) {
gbm.trainerror[i] <- mean((predict(gbm, data_train, n.trees = i) > 0) != gbm.data_train$V58)
gbm.testerror[i] <- mean((predict(gbm, data_test, n.trees = i) > 0) != gbm.data_test$V58)
}
errorDf <- cbind(ada.trainerror, ada.testerror, gbm.trainerror, gbm.testerror)
setwd("~/DATASCIENCE/2_Trimester/15D012ACM/problemSets/PS6")
data <- read.csv("~/DATASCIENCE/2_Trimester/15D012ACM/problemSets/PS5/spambase.data", header=FALSE)
formula <- V58~.
depth = 10
noTrees = 50
if (!require("caret")) install.packages("caret"); library(caret)
if (!require("gbm")) install.packages("gbm"); library(gbm)
if (!require("ggplot")) install.packages("ggplot"); library(ggplot)
#  define rows to partition
part <- createDataPartition(data$V58, p=0.80, list=FALSE)
#  generate train and test sets
data_train <- data[part, ]
data_test <- data[-part, ]
source("adaBoost.R")
result <- adaBoost(formula = formula, data = data_train, depth = 10, noTrees = 20)
ada.trainerror <- result$error
result <- adaBoost(formula = formula, data = data_train, depth = 10, noTrees = 50)
ada.trainerror <- result$error
ada.test <- adaBoost.test(result = result, testData = data_test[ ,-58], testLabels = data_test[ ,58])
adaBoost.test <- function(result, testData, testLabels) {
#  set classes to {1,-1}
y <- ifelse( testLabels==1, 1, -1)
#  initialize
noObs <- length(y)
n <- length(result$datamatrix)
alpha <- result$alpha
#  to store prediction labels and error
ada.predLabels <- matrix(NA, nrow = nrow(testData), ncol = n)
ada.testerror <- rep(NA, n)
for(i in 1:n) {
#  predict labels and store
ada.predLabels[ ,i] <- predict(result$datamatrix[[i]], testData, type="class")
ada.predLabels[ ,i] <- ifelse(ada.predLabels[ ,i]==2, 1, -1)
#  output the sign of a combination of all classifier outputs
ada.finalPred <- sign(rowSums(t(alpha[1:i] * t(ada.predLabels[ ,1:i]))))
#  final prediction error
ada.testerror[i] <- 1 - sum(ada.finalPred == y)/noObs #}
}
return(list(error=ada.testerror))
}
ada.test <- adaBoost.test(result = result, testData = data_test[ ,-58], testLabels = data_test[ ,58])
ada.testerror <- ada.test$error
adaerros <- cbind(ada.trainerror, ada.testerror)
View(adaerros)
#  set classes in datasets to {0, 1} as reqd by gbm
gbm.data_train <- data_train
gbm.data_test <- data_test
gbm.data_train$V58 <- ifelse( gbm.data_train$V58==1, 1, 0)
gbm.data_test$V58 <- ifelse( gbm.data_test$V58==1, 1, 0)
#  call gbm adaboost
gbm <- gbm(formula = formula,
distribution = "adaboost",
data = gbm.data_test,
n.trees = noTrees,
interaction.depth = depth,
shrinkage = 1, bag.fraction = 1)
#  initialize error vectors
gbm.trainerror <- rep(NA, noTrees)
gbm.testerror <- rep(NA, noTrees)
for (i in 1:noTrees) {
gbm.trainerror[i] <- mean((predict(gbm, data_train, n.trees = i) > 0) != gbm.data_train$V58)
gbm.testerror[i] <- mean((predict(gbm, data_test, n.trees = i) > 0) != gbm.data_test$V58)
}
errorDf <- cbind(ada.trainerror, ada.testerror, gbm.trainerror, gbm.testerror)
errorDf
View(errorDf)
df <- data.frame(x=rep(x,4), y=c(err_train, err_test, err_trainR, err_testR), class=c(rep("train.error", 50), rep("test.error",50), rep("package.train.error", 50), rep("package.test.error", 50)))
df <- data.frame(x=rep(x,4),
y=c(ada.trainerror, ada.testerror, gbm.trainerror, gbm.testerror),
class=c(rep("train.error", 50), rep("test.error",50), rep("package.train.error", 50), rep("package.test.error", 50)))
df <- data.frame(x=rep(c(1:50),4),
y=c(ada.trainerror, ada.testerror, gbm.trainerror, gbm.testerror),
class=c(rep("train.error", 50), rep("test.error",50), rep("package.train.error", 50), rep("package.test.error", 50)))
View(df)
setwd("~/DATASCIENCE/2_Trimester/14C007DVIZ/PS1")
By.Month <- read.csv("~/DATASCIENCE/2_Trimester/14C007DVIZ/PS1/By Month", sep="")
By.Month[By.Month == 0] <- NA
View(By.Month)
By.Month2 <- By.Month[c(2,11,21,31,41,51,61,71,81,91,96),]
library(reshape2)
newDF2 = melt(By.Month2, id='Date')
View(newDF2)
View(By.Month)
View(By.Month2)
library(reshape2)
View(errorDf)
rownames(errorDf) <- rownames
rownames(errorDf)
rownames(errorDf) <- 1:50
row <- rownames(errorDf)
newerrorDf = melt(errorDf, id='row')
View(newerrorDf)
setwd("~/DATASCIENCE/2_Trimester/15D012ACM/problemSets/PS6")
data <- read.csv("~/DATASCIENCE/2_Trimester/15D012ACM/problemSets/PS5/spambase.data", header=FALSE)
formula <- V58~.
depth = 10
noTrees = 50
#########################
##  load reqd libraries
#########################
if (!require("caret")) install.packages("caret"); library(caret)
if (!require("gbm")) install.packages("gbm"); library(gbm)
if (!require("ggplot")) install.packages("ggplot"); library(ggplot)
#######################
##  partition data
#######################
#  define rows to partition
part <- createDataPartition(data$V58, p=0.80, list=FALSE)
#  generate train and test sets
data_train <- data[part, ]
data_test <- data[-part, ]
######################################
##  train and test using own adaBoost
######################################
##  train with the training set
source("adaBoost.R")
result <- adaBoost(formula = formula, data = data_train, depth = 10, noTrees = 50)
ada.trainerror <- result$error
##  evaluate performance on test set
adaBoost.test <- function(result, testData, testLabels) {
#  set classes to {1,-1}
y <- ifelse( testLabels==1, 1, -1)
#  initialize
noObs <- length(y)
n <- length(result$datamatrix)
alpha <- result$alpha
#  to store prediction labels and error
ada.predLabels <- matrix(NA, nrow = nrow(testData), ncol = n)
ada.testerror <- rep(NA, n)
for(i in 1:n) {
#  predict labels and store
ada.predLabels[ ,i] <- predict(result$datamatrix[[i]], testData, type="class")
ada.predLabels[ ,i] <- ifelse(ada.predLabels[ ,i]==2, 1, -1)
#  output the sign of a combination of all classifier outputs
ada.finalPred <- sign(rowSums(t(alpha[1:i] * t(ada.predLabels[ ,1:i]))))
#  final prediction error
ada.testerror[i] <- 1 - sum(ada.finalPred == y)/noObs #}
}
return(list(error=ada.testerror))
}
#  call function to retrieve test error
ada.test <- adaBoost.test(result = result, testData = data_test[ ,-58], testLabels = data_test[ ,58])
ada.testerror <- ada.test$error
######################################
##  Compare error with GBM package
######################################
#  set classes in datasets to {0, 1} as reqd by gbm
gbm.data_train <- data_train
gbm.data_test <- data_test
gbm.data_train$V58 <- ifelse( gbm.data_train$V58==1, 1, 0)
gbm.data_test$V58 <- ifelse( gbm.data_test$V58==1, 1, 0)
#  call gbm adaboost
gbm <- gbm(formula = formula,
distribution = "adaboost",
data = gbm.data_test,
n.trees = noTrees,
interaction.depth = depth,
shrinkage = 1, bag.fraction = 1)
#  initialize error vectors
gbm.trainerror <- rep(NA, noTrees)
gbm.testerror <- rep(NA, noTrees)
for (i in 1:noTrees) {
gbm.trainerror[i] <- mean((predict(gbm, data_train, n.trees = i) > 0) != gbm.data_train$V58)
gbm.testerror[i] <- mean((predict(gbm, data_test, n.trees = i) > 0) != gbm.data_test$V58)
}
#####################
##  Compare Results
#####################
pdf("Compare adaBoost")
df <- data.frame(x=rep(c(1:50),4),
y=c(ada.trainerror, ada.testerror, gbm.trainerror, gbm.testerror),
class=c(rep("train.error", 50), rep("test.error",50), rep("package.train.error", 50), rep("package.test.error", 50)))
rm(df)
errorDf <- cbind(ada.trainerror, ada.testerror, gbm.trainerror, gbm.testerror)
View(errorDf)
rownames(errorDf) <- 1:50
row <- rownames(errorDf)
View(errorDf)
new.errorDf = melt(errorDf, id='row')
View(errorDf)
View(new.errorDf)
View(new.errorDf)
rownames(new.errorDf) <- c("noTrees", "Error Type", "Error Rate")
rownames(new.errorDf)
colnames(new.errorDf) <- c("noTrees", "Error Type", "Error Rate")
View(new.errorDf)
pdf("Compare adaBoost", width=8, height=4.5)
ggplot(data = new.errorDf, aes(x = X, y = y,colors="Error Type", fill=Deny)) +
geom_point() +
xlab("noTrees") +
ylab("Misclassification Error") +
theme_bw(base_size = 14, base_family = "Helvetica")
pdf("Compare adaBoost", width=8, height=4.5)
ggplot(data = new.errorDf, aes(x = x, y = y,colors="Error Type", fill=Deny)) +
geom_point() +
xlab("noTrees") +
ylab("Misclassification Error") +
theme_bw(base_size = 14, base_family = "Helvetica")
ggplot(data = new.errorDf, aes(x ="noTrees", y ="Error Rate",colors="Error Type", fill=Deny)) +
geom_point() +
xlab("noTrees") +
ylab("Misclassification Error") +
theme_bw(base_size = 14, base_family = "Helvetica")
ggplot(data = new.errorDf, aes(x ="noTrees", y ="Error Rate",colors="Error Type", fill="Error Type")) +
geom_point() +
xlab("noTrees") +
ylab("Misclassification Error") +
theme_bw(base_size = 14, base_family = "Helvetica")
dev.off()
pdf("Compare adaBoost", width=8, height=4.5)
ggplot(data = new.errorDf, aes(x ="noTrees", y ="Error Rate",colors="Error Type", fill="Error Type")) +
geom_point() +
xlab("noTrees") +
ylab("Misclassification Error") +
theme_bw(base_size = 14, base_family = "Helvetica")
dev.off()
ggplot(data = new.errorDf, aes(x ="noTrees", y ="Error Rate",colors="Error Type", fill="Error Type")) +
geom_point() +
xlab("noTrees") +
ylab("Misclassification Error") +
theme_bw(base_size = 14, base_family = "Helvetica")
dev.off()
?aes
View(new.errorDf)
df <- data.frame(x=rep(c(1:50),4),
y=c(err_train, err_test, err_trainR, err_testR),
class=c(rep("train.error", 50), rep("test.error",50), rep("package.train.error", 50), rep("package.test.error", 50)))
df <- data.frame(x=rep(c(1:50),4),
y=c(ada.trainerror, ada.testerror, gbm.trainerror, gbm.testerror),
class=c(rep("train.error", 50), rep("test.error",50), rep("package.train.error", 50), rep("package.test.error", 50)))
View(df)
View(df)
View(new.errorDf)
g<- ggplot(data = new.errorDf, aes(x ="noTrees", y ="Error Rate",colors="Error Type")) +
geom_point() +
xlab("noTrees") +
ylab("Misclassification Error") +
theme_bw(base_size = 14, base_family = "Helvetica")
g
setwd("~/DATASCIENCE/2_Trimester/15D012ACM/problemSets/PS6")
pdf("Compare adaBoost", width=8, height=4.5)
g <- ggplot(data = new.errorDf, aes(x ="noTrees", y ="Error Rate",colors="Error Type")) +
geom_point() +
xlab("noTrees") +
ylab("Misclassification Error") +
theme_bw(base_size = 14, base_family = "Helvetica")
dev.off()
plot.pdf <- function(Df){
pdf("Compare adaBoost.pdf", width=8, height=5)
plot <-ggplot(data = new.errorDf, aes(x ="noTrees", y ="Error Rate",colors="Error Type")) +
geom_point() +
xlab("noTrees") +
ylab("Misclassification Error") +
theme_bw(base_size = 14, base_family = "Helvetica")
print(plot)
dev.off()
}
plot.pdf(new.errorDf)
rm(plot.pdf)
pdf("Compare adaBoost.pdf", width=8, height=4.5)
g <- ggplot(data = new.errorDf, aes(x ="noTrees", y ="Error Rate",colors="Error Type")) +
geom_point() +
xlab("noTrees") +
ylab("Misclassification Error") +
theme_bw(base_size = 14, base_family = "Helvetica")
dev.off()
if (!require("ggplot")) install.packages("ggplot"); library(ggplot)
if (!require("ggplot2")) install.packages("ggplot"); library(ggplot2)
pdf("Compare adaBoost.pdf", width=8, height=4.5)
ggplot(data = new.errorDf, aes(x ="noTrees", y ="Error Rate",colors="Error Type")) +
geom_point() +
xlab("noTrees") +
ylab("Misclassification Error") +
theme_bw(base_size = 14, base_family = "Helvetica")
dev.off()
library(ggplot2)
pdf("Compare adaBoost.pdf", width=8, height=4.5)
ggplot(data = new.errorDf, aes(x ="noTrees", y ="Error Rate",colors="Error Type")) +
geom_point() +
xlab("noTrees") +
ylab("Misclassification Error") +
theme_bw()
ggplot(data = new.errorDf, aes(x ="noTrees", y ="Error Rate",colors="Error Type")) +
geom_point() +
xlab("noTrees") +
ylab("Misclassification Error") +
theme_bw()
ggplot(new.errorDf)
